{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Next Character Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1geCtFicEoPtFDrMmR-qgp8vPzktRb-Y5",
      "authorship_tag": "ABX9TyMeSKRdOrnWTDCHujSl9Y8I"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models, layers, callbacks\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IFYVtcED0z7I"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-L6ZegBR2at"
      },
      "source": [
        "# The train, val and test sets are present in this drive link\n",
        "# Please download the files and upload them in the content folder first\n",
        "\n",
        "# https://drive.google.com/drive/folders/12GqRiyFHPUauuY0IIMlycVPRv_DuG5FI?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/Datasets/Sentiment Analysis/train.txt', sep = ';', names = ['Text', 'Mood'])\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/Datasets/Sentiment Analysis/val.txt', sep = ';', names = ['Text', 'Mood'])\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/Datasets/Sentiment Analysis/test.txt', sep = ';', names = ['Text', 'Mood'])\n",
        "\n",
        "df = pd.concat([df1, df2, df3])\n",
        "df = df.iloc[:, 0].tolist()"
      ],
      "metadata": {
        "id": "t5r4jiTW03iI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the vocabulary from the training set\n",
        "\n",
        "def create_vocab(df, r):\n",
        "  vocab = {}\n",
        "  c = 0\n",
        "\n",
        "  for i in df:\n",
        "    if r==1:\n",
        "      i = i.split()\n",
        "    for k in i:\n",
        "\n",
        "      if k not in vocab.keys():\n",
        "        vocab[k] = c\n",
        "        c = c + 1\n",
        "\n",
        "  return vocab"
      ],
      "metadata": {
        "id": "9KbzS88nUZ1a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def divide(n, vocab, df, r):\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in df:\n",
        "    if r==1:\n",
        "      i = i.split()\n",
        "\n",
        "    if len(i)>=n:\n",
        "      for j in range(len(i)-n+1):\n",
        "        x = []\n",
        "        for k in range(n-1):\n",
        "          x.append(vocab[i[j+k]])\n",
        "        y.append([vocab[i[j+n-1]]])\n",
        "        X.append(x)\n",
        "\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "xxRDbE9SzXN-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = int(input(\"0 for character; 1 for word: \"))\n",
        "n = int(input(\"Enter (number of input)+1 characters/words: \"))\n",
        "v = create_vocab(df, r)\n",
        "X, y = divide(n, v, df, r)"
      ],
      "metadata": {
        "id": "6Y4fCNU9fErT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c62a99c-3833-4ffe-83b7-8ebf7c31155f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 for character; 1 for word: 0\n",
            "Enter (number of input)+1 characters/words: 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
        "\n",
        "X_train = np.array(X_train[0:100000])\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train[0:100000])\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "1ZZMDSaCRfca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is required if we do not use the embedding layer\n",
        "\n",
        "# X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1])).astype('float64')\n",
        "# X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1])).astype('float64')"
      ],
      "metadata": {
        "id": "ntavXEIxsQx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the actual model\n",
        "\n",
        "model = models.Sequential([\n",
        "        layers.Embedding(len(v), 30),\n",
        "        # layers.LSTM(128, return_sequences=True),\n",
        "        layers.LSTM(128, return_sequences=True),\n",
        "        layers.LSTM(100),\n",
        "        # layers.Dense(100, activation='relu'),\n",
        "        layers.Dense(100, activation='relu'),\n",
        "        layers.Dense(len(v), activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], optimizer='adam')\n",
        "ES = callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, validation_split=0.1, epochs=50, callbacks=[ES])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0m6W4Igh40G",
        "outputId": "2a920be7-11e2-4935-f73d-5de1c84435be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2813/2813 [==============================] - 510s 180ms/step - loss: 2.3545 - accuracy: 0.3093 - val_loss: 2.0347 - val_accuracy: 0.3933\n",
            "Epoch 2/50\n",
            "2813/2813 [==============================] - 506s 180ms/step - loss: 1.9393 - accuracy: 0.4148 - val_loss: 1.8228 - val_accuracy: 0.4469\n",
            "Epoch 3/50\n",
            "2813/2813 [==============================] - 505s 179ms/step - loss: 1.7711 - accuracy: 0.4572 - val_loss: 1.7162 - val_accuracy: 0.4716\n",
            "Epoch 4/50\n",
            "2813/2813 [==============================] - 504s 179ms/step - loss: 1.6635 - accuracy: 0.4879 - val_loss: 1.6440 - val_accuracy: 0.4990\n",
            "Epoch 5/50\n",
            "2813/2813 [==============================] - 508s 180ms/step - loss: 1.5825 - accuracy: 0.5116 - val_loss: 1.6105 - val_accuracy: 0.5096\n",
            "Epoch 6/50\n",
            "2813/2813 [==============================] - 517s 184ms/step - loss: 1.5211 - accuracy: 0.5268 - val_loss: 1.5801 - val_accuracy: 0.5168\n",
            "Epoch 7/50\n",
            "2813/2813 [==============================] - 510s 181ms/step - loss: 1.4678 - accuracy: 0.5420 - val_loss: 1.5715 - val_accuracy: 0.5209\n",
            "Epoch 8/50\n",
            "2813/2813 [==============================] - 508s 180ms/step - loss: 1.4233 - accuracy: 0.5560 - val_loss: 1.5609 - val_accuracy: 0.5270\n",
            "Epoch 9/50\n",
            "2813/2813 [==============================] - 507s 180ms/step - loss: 1.3836 - accuracy: 0.5663 - val_loss: 1.5448 - val_accuracy: 0.5284\n",
            "Epoch 10/50\n",
            "2813/2813 [==============================] - 508s 180ms/step - loss: 1.3477 - accuracy: 0.5747 - val_loss: 1.5400 - val_accuracy: 0.5377\n",
            "Epoch 11/50\n",
            "2813/2813 [==============================] - 509s 181ms/step - loss: 1.3135 - accuracy: 0.5867 - val_loss: 1.5403 - val_accuracy: 0.5369\n",
            "Epoch 12/50\n",
            "2813/2813 [==============================] - 507s 180ms/step - loss: 1.2839 - accuracy: 0.5940 - val_loss: 1.5575 - val_accuracy: 0.5380\n",
            "Epoch 13/50\n",
            "2813/2813 [==============================] - 507s 180ms/step - loss: 1.2590 - accuracy: 0.6009 - val_loss: 1.5609 - val_accuracy: 0.5348\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa796db8250>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_p = []\n",
        "\n",
        "for i in y_pred:\n",
        "  m = list(i).index(max(i))\n",
        "  y_p.append(m)\n",
        "y_test = np.reshape(y_test, (-1))\n",
        "\n",
        "n = (y_p==y_test).sum()\n",
        "acc = n/len(y_test)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN0f6SVzWYJa",
        "outputId": "b7b11cc4-44cf-47e4-a9d1-60bd60f7b5be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5369556867828509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom(n, vocab, inp):\n",
        "  x = []\n",
        "  l = 1\n",
        "\n",
        "  if len(inp)==n:\n",
        "    for i in inp:\n",
        "      x.append(vocab[i])\n",
        "\n",
        "  else:\n",
        "    l = 0\n",
        "    print(\"Current length: \", len(inp))\n",
        "    print(\"Enter a text of len: \", n)\n",
        "\n",
        "  return [x], l"
      ],
      "metadata": {
        "id": "4OaY8JIcE9BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4o8KtQrMACJ",
        "outputId": "94914fae-5206-43c3-e979-d40565bdc081"
      },
      "source": [
        "t = input(\"Enter the text: \")\n",
        "t_, j = custom(100, v, t)\n",
        "\n",
        "if j==1:\n",
        "  x = int(input(\"Enter the number of char to be predicted: \"))\n",
        "  print(\"The complete output is:\\n\")\n",
        "  print(t, end='')\n",
        "  for _ in range(x):\n",
        "    pred = model.predict(t_)\n",
        "    y = list(v.keys())\n",
        "    z = list(v.values())\n",
        "    m = list(pred[0]).index(max(pred[0]))\n",
        "    val = y[z.index(m)]\n",
        "    print(val, end='')\n",
        "    t_[0].pop(0)\n",
        "    t_[0].append(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: i feel that i m so pathetic and downright dumb to let people in let them toy with my feelings and th\n",
            "Enter the number of char to be predicted: 40\n",
            "The complete output is:\n",
            "\n",
            "i feel that i m so pathetic and downright dumb to let people in let them toy with my feelings and the struggled to the struggled to be a bal"
          ]
        }
      ]
    }
  ]
}